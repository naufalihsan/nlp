{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Probabilistic Language Modeling\n",
        "\n",
        "> Language models offer a way to assign a probability to a sentence or other sequence of words, and to predict a word from preceding words."
      ],
      "metadata": {
        "id": "Ebsj6scS-TQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The chain rule of probability**\n",
        "\n",
        "$P(w_1,w_2,\\ldots,w_n) = \\prod P(w_i \\mid w_{1}, w_{2}, \\ldots, w_{i-1})$"
      ],
      "metadata": {
        "id": "bsOQ8JM7BpvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Markov assumption**\n",
        "\n",
        "$P(w_{i} \\mid w_1, w_2, \\ldots, w_{i-1}) \\approx P(w_{i} \\mid w_{i-k}, \\ldots,w_{i-1})$"
      ],
      "metadata": {
        "id": "fCRJyaalDXHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### N-Grams\n",
        "\n",
        "> n-grams are Markov models that estimate words from a fixed window of previous words. n-gram probabilities can be estimated by counting in a corpus and normalizing (the **maximum likelihood estimate**)."
      ],
      "metadata": {
        "id": "-Dr79z1JAlls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_D8fwx8S2YDV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/berkeley_restaurant.csv', index_col=0)"
      ],
      "metadata": {
        "id": "1qcbE6U2xpNX"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "velDfR-k0VKI",
        "outputId": "225625c7-a4e1-4a70-961d-480a87696294"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "_zQBwXTxRd-D"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padded_tokens(text):\n",
        "  prefix, suffix = '<s>', '</s>'\n",
        "  return [prefix] + word_tokenize(text) + [suffix]"
      ],
      "metadata": {
        "id": "tTcYrbrQtSlq"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokens'] = df['text'].apply(lambda text: padded_tokens(text))"
      ],
      "metadata": {
        "id": "7G-RYdk10GC1"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "tgZQKK6g0bsu"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['unigram'] = df['tokens'].apply(lambda tokens: list((ngrams(tokens, 1))))"
      ],
      "metadata": {
        "id": "fMFsotL12wQY"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bigram'] = df['tokens'].apply(lambda tokens: list((ngrams(tokens, 2))))"
      ],
      "metadata": {
        "id": "iyumUaHQTHYi"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "pVjHUlXh3BFh",
        "outputId": "54ef5c00-d262-47e2-efd7-db0b0af2e33e"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  okay lets see i want to go to a thai restauran...   \n",
              "1  i like to eat uh i like to eat at lunch time s...   \n",
              "2     i dont want to walk for more than five minutes   \n",
              "3  tell me more about the uh na nakapan uh restau...   \n",
              "4             i like to go to a hamburger restaurant   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [<s>, okay, lets, see, i, want, to, go, to, a,...   \n",
              "1  [<s>, i, like, to, eat, uh, i, like, to, eat, ...   \n",
              "2  [<s>, i, dont, want, to, walk, for, more, than...   \n",
              "3  [<s>, tell, me, more, about, the, uh, na, naka...   \n",
              "4  [<s>, i, like, to, go, to, a, hamburger, resta...   \n",
              "\n",
              "                                             unigram  \\\n",
              "0  [(<s>,), (okay,), (lets,), (see,), (i,), (want...   \n",
              "1  [(<s>,), (i,), (like,), (to,), (eat,), (uh,), ...   \n",
              "2  [(<s>,), (i,), (dont,), (want,), (to,), (walk,...   \n",
              "3  [(<s>,), (tell,), (me,), (more,), (about,), (t...   \n",
              "4  [(<s>,), (i,), (like,), (to,), (go,), (to,), (...   \n",
              "\n",
              "                                              bigram  \n",
              "0  [(<s>, okay), (okay, lets), (lets, see), (see,...  \n",
              "1  [(<s>, i), (i, like), (like, to), (to, eat), (...  \n",
              "2  [(<s>, i), (i, dont), (dont, want), (want, to)...  \n",
              "3  [(<s>, tell), (tell, me), (me, more), (more, a...  \n",
              "4  [(<s>, i), (i, like), (like, to), (to, go), (g...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7ca9e67-9707-458f-8db9-404b31e531c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>unigram</th>\n",
              "      <th>bigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>okay lets see i want to go to a thai restauran...</td>\n",
              "      <td>[&lt;s&gt;, okay, lets, see, i, want, to, go, to, a,...</td>\n",
              "      <td>[(&lt;s&gt;,), (okay,), (lets,), (see,), (i,), (want...</td>\n",
              "      <td>[(&lt;s&gt;, okay), (okay, lets), (lets, see), (see,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i like to eat uh i like to eat at lunch time s...</td>\n",
              "      <td>[&lt;s&gt;, i, like, to, eat, uh, i, like, to, eat, ...</td>\n",
              "      <td>[(&lt;s&gt;,), (i,), (like,), (to,), (eat,), (uh,), ...</td>\n",
              "      <td>[(&lt;s&gt;, i), (i, like), (like, to), (to, eat), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i dont want to walk for more than five minutes</td>\n",
              "      <td>[&lt;s&gt;, i, dont, want, to, walk, for, more, than...</td>\n",
              "      <td>[(&lt;s&gt;,), (i,), (dont,), (want,), (to,), (walk,...</td>\n",
              "      <td>[(&lt;s&gt;, i), (i, dont), (dont, want), (want, to)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me more about the uh na nakapan uh restau...</td>\n",
              "      <td>[&lt;s&gt;, tell, me, more, about, the, uh, na, naka...</td>\n",
              "      <td>[(&lt;s&gt;,), (tell,), (me,), (more,), (about,), (t...</td>\n",
              "      <td>[(&lt;s&gt;, tell), (tell, me), (me, more), (more, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i like to go to a hamburger restaurant</td>\n",
              "      <td>[&lt;s&gt;, i, like, to, go, to, a, hamburger, resta...</td>\n",
              "      <td>[(&lt;s&gt;,), (i,), (like,), (to,), (go,), (to,), (...</td>\n",
              "      <td>[(&lt;s&gt;, i), (i, like), (like, to), (to, go), (g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ca9e67-9707-458f-8db9-404b31e531c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7ca9e67-9707-458f-8db9-404b31e531c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7ca9e67-9707-458f-8db9-404b31e531c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maximum Likelihood Estimate**\n",
        "\n",
        "$P(W_i \\mid W_{i-1}) = \\frac{count(W_{i-1}, W_i)}{count(W_{i-1})}$"
      ],
      "metadata": {
        "id": "qDuODhdqcfos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "ZcryJaK5YIRR"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_counts = Counter(df['unigram'].explode())"
      ],
      "metadata": {
        "id": "v4_oaja-iNvq"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts = Counter(df['bigram'].explode())"
      ],
      "metadata": {
        "id": "VX4CePBQ3zup"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_proba(bigram_counts, unigram_counts):\n",
        "  proba = {}\n",
        "  for bigram in bigram_counts.keys():\n",
        "    try:\n",
        "      prev_word, word = bigram\n",
        "      proba[bigram] = bigram_counts.get(bigram) / unigram_counts.get((prev_word,))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  return proba"
      ],
      "metadata": {
        "id": "OYaySiI532xo"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proba = bigram_proba(bigram_counts, unigram_counts)"
      ],
      "metadata": {
        "id": "3uPxiZ1x34Hh"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_txt = 'i want english food'"
      ],
      "metadata": {
        "id": "6tmuJBQ6Wm1j"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw Probabilities**\n",
        "\n",
        "$P(W_1, W_2, \\ldots, W_n) = P(W_2 \\mid W_1) \\times \\ldots \\times P(W_n \\mid W_{n-1})  $"
      ],
      "metadata": {
        "id": "f3zRwiybO_lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(text):\n",
        "  bigrams = list(ngrams(text.split(), 2))\n",
        "  preds = 1\n",
        "  for bigram in bigrams:\n",
        "    preds *= proba.get(bigram, 0)\n",
        "    \n",
        "  return preds"
      ],
      "metadata": {
        "id": "mty-GV4e4vT3"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log Probabilities**\n",
        "\n",
        "$P(W_1, W_2, \\ldots, W_n) = exp(log(P(W_2 \\mid W_1)) + \\ldots + log(P(W_n \\mid W_{n-1})))  $"
      ],
      "metadata": {
        "id": "PR8pT0UIQrj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "7CgmftvwLeY9"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_log_proba(text):\n",
        "  bigrams = list(ngrams(text.split(), 2))\n",
        "  preds = 0\n",
        "  for bigram in bigrams:\n",
        "    preds += math.log(proba.get(bigram, 0))\n",
        "  \n",
        "  return math.exp(preds)"
      ],
      "metadata": {
        "id": "jVM_c0Ek-iim"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_log_proba(sample_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yws9Ci529JTt",
        "outputId": "55660d49-b1d0-4ec9-d7bf-8e0e496a319b"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000154072590536549"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity**\n",
        "\n",
        "The inverse probability of the test set, normalized\n",
        "by the number of words\n",
        "\n",
        "$PP(W) = P(W_1, W_2, \\ldots, W_n)^{-\\frac{1}{N}}$\n",
        "\n",
        "$PP(W) = \\sqrt[N]{\\prod\\frac{1}{P(W_i \\mid W_1 \\ldots W_{i-1})}}$"
      ],
      "metadata": {
        "id": "B4wnMXxXNvxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(text):\n",
        "  n = len(list(ngrams(text.split(), 2)))\n",
        "  p = predict_proba(text)\n",
        "\n",
        "  return math.pow(1/p, 1/n)"
      ],
      "metadata": {
        "id": "y_XArjD6Nwjq"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity(sample_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DQufXKaWiuD",
        "outputId": "2240455e-621f-4426-9dc8-8c6d2e9704f5"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.653408668710675"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generalization and Zeros**\n",
        "- Out of Vocabulary (OOV)"
      ],
      "metadata": {
        "id": "J_lXRxWGuXbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Smoothing**\n",
        "\n",
        "> Smoothing algorithms provide a more sophisticated way to estimate the probability of n-grams. Commonly used smoothing algorithms for n-grams rely on lower-order n-gram counts through backoff or interpolation"
      ],
      "metadata": {
        "id": "eaTkll0hd3X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_smooth_proba(bigram_counts, unigram_counts, smoothing='laplace'):\n",
        "  proba = {}\n",
        "  for bigram in bigram_counts.keys():\n",
        "    try:\n",
        "      V = len(unigram_counts.keys())\n",
        "      prev_word, word = bigram\n",
        "      if smoothing == 'laplace':\n",
        "        proba[bigram] = (bigram_counts.get(bigram) + 1) / (unigram_counts.get((prev_word,)) + V)\n",
        "      elif smoothing == 'add_k':\n",
        "        k = 0.1\n",
        "        proba[bigram] = (bigram_counts.get(bigram) + k) / (unigram_counts.get((prev_word,)) + (k * V))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  return proba"
      ],
      "metadata": {
        "id": "MRrbkj0KWukJ"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Laplace Smoothing**\n",
        "\n",
        "$P_{Laplace}(W_i \\mid W_{i-1}) = \\frac{count(W_{i-1}, W_i) \\: + \\: 1}{count(W_{i-1}) \\: + \\: V}$"
      ],
      "metadata": {
        "id": "V-4J2Op0eplL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laplace_proba = bigram_smooth_proba(bigram_counts, unigram_counts, smoothing='laplace')"
      ],
      "metadata": {
        "id": "qOMQca3KhdQy"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add-k Smoothing**\n",
        "\n",
        "$P_{Add-k}(W_i \\mid W_{i-1}) = \\frac{count(W_{i-1}, W_i) \\: + \\: k}{count(W_{i-1}) \\: + \\: kV}$"
      ],
      "metadata": {
        "id": "lSp6Rp6CikNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_k_proba = bigram_smooth_proba(bigram_counts, unigram_counts, smoothing='add_k')"
      ],
      "metadata": {
        "id": "pml4xZuPkOme"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_smooth_proba(text, smoothing='laplace'):\n",
        "  bigrams = list(ngrams(text.split(), 2))\n",
        "  preds = 1\n",
        "  for bigram in bigrams:\n",
        "    if smoothing == 'laplace':\n",
        "      preds *= laplace_proba.get(bigram, 0)\n",
        "    elif smoothing == 'add_k':\n",
        "      preds *= add_k_proba.get(bigram, 0)\n",
        "\n",
        "  return preds"
      ],
      "metadata": {
        "id": "FDfmQrw6hj3f"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_smooth_proba(sample_txt, smoothing='laplace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUBpaDJrh-YM",
        "outputId": "2afd0acb-092b-4a42-84f9-06c610c0c5d4"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.941694493179284e-07"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_smooth_proba(sample_txt, smoothing='add_k')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBnOi9_Ah_m8",
        "outputId": "749b9c3d-4d00-4966-d96b-2cb8c8b15661"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8859943386849113e-06"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Smoothing**\n",
        "- Stupid Backoff (For very large N-grams like web)\n",
        "- Kneser-Ney smoothing"
      ],
      "metadata": {
        "id": "kSpNAxFBk9NO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexityâ€™s Relation to Entropy**"
      ],
      "metadata": {
        "id": "fDo_oyjiunzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Language Modeling Toolkits**\n",
        "- SRILM\n",
        "- KenLM"
      ],
      "metadata": {
        "id": "XXVT9omFObrn"
      }
    }
  ]
}