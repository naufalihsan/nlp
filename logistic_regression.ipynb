{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Spam Detection"
      ],
      "metadata": {
        "id": "KKj7R_3zyFCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xwLEL1zdQ_n",
        "outputId": "fcbc2b4b-ebd3-4e30-85ef-0d7852afc8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "BxPwLf_QdSr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUOkXRWqRkpw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_table('/content/SMSSpamCollection', header=None, encoding='utf-8')"
      ],
      "metadata": {
        "id": "zJ09Bs-zZfkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-15DufBKb2pw",
        "outputId": "66efd6ff-4f42-4d25-f32f-61e1500e58d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0                                                  1\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3d0ed79-353d-427c-bea3-4744f740349d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3d0ed79-353d-427c-bea3-4744f740349d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3d0ed79-353d-427c-bea3-4744f740349d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3d0ed79-353d-427c-bea3-4744f740349d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sms(sms):\n",
        "  # case folding\n",
        "  sms = sms.lower()\n",
        "\n",
        "  # replace email addresses with 'email'\n",
        "  sms = re.sub(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'email', sms)\n",
        "  \n",
        "  # replace URLs with 'web'\n",
        "  sms = re.sub(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'web', sms)\n",
        "  \n",
        "  # replace money symbols with 'currency' (£ can by typed with ALT key + 156)\n",
        "  sms = re.sub(r'£|\\$', 'currency', sms)\n",
        "  \n",
        "  # replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phone'\n",
        "  sms = re.sub(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phone', sms)\n",
        "  \n",
        "  # replace numbers with 'number'\n",
        "  sms = re.sub(r'\\d+(\\.\\d+)?', 'number', sms)\n",
        "  \n",
        "  # remove useless character\n",
        "  sms = re.sub(r'[^\\w\\d\\s]', ' ', sms)\n",
        "  \n",
        "  # replace whitespace between terms with a single space\n",
        "  sms = re.sub(r'\\s+', ' ', sms)\n",
        "  \n",
        "  # remove leading and trailing whitespace\n",
        "  sms = re.sub(r'^\\s+|\\s+?$', '', sms)\n",
        "\n",
        "  # tokenize sms\n",
        "  sms_tokens = word_tokenize(sms)\n",
        "  \n",
        "  stopwords_english = stopwords.words('english')\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  clean_sms = []\n",
        "  for word in sms_tokens:\n",
        "    if word not in stopwords_english:\n",
        "      stem_word = stemmer.stem(word)\n",
        "      clean_sms.append(stem_word)\n",
        "\n",
        "  return clean_sms"
      ],
      "metadata": {
        "id": "sjgysDwWbA2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df[1].apply(lambda sms: preprocess_sms(sms))"
      ],
      "metadata": {
        "id": "5DVfs71BdKlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Yk5_iNy8gnGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "jacYnxuLjMyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = le.fit_transform(df[0])"
      ],
      "metadata": {
        "id": "prsHwwJfhNxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(le.classes_, range(len(le.classes_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ1FJyIlCjwg",
        "outputId": "521ed986-e760-4d16-ab02-df9737042928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ham': 0, 'spam': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LW_QzGG2QaGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['label'].to_numpy()"
      ],
      "metadata": {
        "id": "l3zgQKqLQhNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21, stratify=y)"
      ],
      "metadata": {
        "id": "pOJt8JfuQbGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Engineering"
      ],
      "metadata": {
        "id": "gt0g7jiijwC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(texts, labels):\n",
        "  freqs = {}\n",
        "  for text, label in zip(texts, labels):\n",
        "    for word in text:\n",
        "      pair = (word, label)\n",
        "      freqs[pair] = freqs.get(pair, 0) + 1\n",
        "\n",
        "  return freqs"
      ],
      "metadata": {
        "id": "YTs9G8p4opaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = bag_of_words(X_train, y_train)"
      ],
      "metadata": {
        "id": "P64un6k8pe-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(text, freqs):\n",
        "  features = np.zeros((1, 3))\n",
        "\n",
        "  features[0,0] = 1 # bias\n",
        "\n",
        "  for word in text:\n",
        "    features[0,1] += freqs.get((word, 1), 0)\n",
        "    features[0,2] += freqs.get((word, 0), 0)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "2ntRbpAspkcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = X_train[0]"
      ],
      "metadata": {
        "id": "YaJ0mIq3RIuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(sample_text, freqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O58UPnb7pnTD",
        "outputId": "8dad2790-8441-4530-c932-9d49b39de768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.,  83., 922.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression\n",
        "\n",
        "Logistic regression is a supervised machine learning classifier that extracts real-valued features from the input, multiplies each by a weight, sums them, and passes the sum through a sigmoid function to generate a probability"
      ],
      "metadata": {
        "id": "mEEXXXbbDXkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Sigmoid Function\n",
        "\n",
        "Consider a single input observation $x$, which we will represent by a vector of features $[x_1, x_2, \\ldots, x_n]$. \n",
        "\n",
        "We want to know the probability $P(y \\mid x)$ that this observation is a member of the class\n"
      ],
      "metadata": {
        "id": "H3JBwDkUrgCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression solves this task by learning, from a training set, a vector of weights and bias term / intercept"
      ],
      "metadata": {
        "id": "K0zfSy9Q0Skw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make a decision on a test instance after we’ve learned the weights in training the classifier first multiplies each $x_i$ by its weight $w_i$, sums up the weighted features, and adds the bias term $b$. The resulting single number $z$ expresses the weighted sum\n",
        "of the evidence for the class"
      ],
      "metadata": {
        "id": "A8TIivFBxtQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "z = \\left(\\sum_{i=1}^{n} w_i x_i\\right) + b  = w \\cdot x + b\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "zlOGODnbyOiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sigmoid function $\\sigma(z)$ takes a real value and maps it to the range (0,1)"
      ],
      "metadata": {
        "id": "LYLtHHPuy_Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "XBmpwbxW0doY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "AmFzMLQk06wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classification with Logistic Regression"
      ],
      "metadata": {
        "id": "a_Kjx4oL2Pht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "    decision(x)= \n",
        "\\begin{cases}\n",
        "    1, & \\text{if } P(y \\mid x) > 0.5 \\\\\n",
        "    0, & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "WejRsF-e2uHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Learning in Logistic Regression\n",
        "\n",
        "We want to learn parameters ($w$ and $b$) that make $\\widehat{y}$ for each training observation as close as possible to the true $y$. This requires two components\n",
        "\n",
        "1. **Loss function** distance between the system output and the gold output\n",
        "2. **Optimization algorithm** iteratively updating the weights so as to minimize this loss function"
      ],
      "metadata": {
        "id": "xCdlu19M45vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The cross-entropy loss function\n",
        "\n",
        "The weights (vector w and bias b) are learned from a labeled training set via a loss function, that must be minimized."
      ],
      "metadata": {
        "id": "HHwtu78d3w0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conditional Maximum Likelihood Estimation** choose the parameters $w, b$ that maximize the log probability of the true $y$ labels in the training data given the observations $x$. \n",
        "\n",
        "The resulting loss function is the negative log likelihood loss"
      ],
      "metadata": {
        "id": "UunIB4kk-bX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’d like to learn weights that maximize the probability of the correct label $P(y \\mid x)$. Since there are only two discrete outcomes this is a **Bernoulli distribution**"
      ],
      "metadata": {
        "id": "J-GTGiYk_B9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "P(y \\mid x) = \\widehat{y}^{\\:y}(1 - \\widehat{y})^{1-y} \n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "bGOl9-M28FRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximize a probability will also maximize the log of the probability"
      ],
      "metadata": {
        "id": "5nJ_ikoqBmt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "log(P(y \\mid x)) &= log\\bigr[\\widehat{y}^{\\:y}(1 - \\widehat{y})^{1-y}\\bigr] \\\\\n",
        "&= y \\: log \\: \\widehat{y} + (1 - y) \\: log(1 - \\widehat{y})\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "26pMjcde_KNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to turn this into a loss function we’ll just flip the sign on"
      ],
      "metadata": {
        "id": "ok4KsX7lKl8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "L_{CE}(\\widehat{y}, y) = -\\bigr[y \\: log \\: \\widehat{y} + (1 - y) \\: log(1 - \\widehat{y})\\bigr]\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "kocA9WrxLNaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch training**\n",
        "\n",
        "The cost function for the batch of m examples is the average loss for each example"
      ],
      "metadata": {
        "id": "QLZDBCbGovGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "Cost(\\widehat{y}, y) = \\frac{1}{m} \\sum_{i=1}^{m} L_{CE}(\\widehat{y}^{(i)}, y^{(i)})\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "X1eTR27Voxfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_hat, y):\n",
        "  return - (np.squeeze(np.matmul(y.T , np.log(y_hat))) + np.squeeze(np.matmul((1 - y).T , np.log(1 - y_hat))))"
      ],
      "metadata": {
        "id": "mNaNkHU8bouu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Descent\n",
        "\n",
        "Minimizing this loss function is a convex optimization problem, and iterative algorithms like gradient descent are used to find the optimal weights."
      ],
      "metadata": {
        "id": "vTlVD2lBMOSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "\\theta^{\\:t+1} = \\theta^{\\:t} - \\eta \\nabla L (f(x;\\theta), y)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "gq8LTrb5wOAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition for the gradient"
      ],
      "metadata": {
        "id": "S9-L638-E4gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "\\nabla L (f(x;\\theta), y) = \\frac{\\partial L_{CE}(\\widehat{y}, y)}{\\partial w_j} = x_j \\: (\\widehat{y} - y)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "dDDVc5SFxMuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_loss(X, y_hat, y):\n",
        "  return np.squeeze(np.matmul(X.T,(y_hat - y)))[:,np.newaxis]"
      ],
      "metadata": {
        "id": "RdaffNs-1CbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, eta=1e-8, epochs=500):\n",
        "  m, f = X.shape\n",
        "  theta = np.zeros((f, 1))\n",
        "  for epoch in range(epochs):\n",
        "    z = np.matmul(X, theta)\n",
        "    y_hat = sigmoid(z)\n",
        "    g = 1 / m * gradient_loss(X, y_hat, y)\n",
        "    theta = theta - eta * g\n",
        "    cost = 1 / m * cross_entropy_loss(y_hat, y)  \n",
        "\n",
        "  return cost, theta  "
      ],
      "metadata": {
        "id": "ck96kGRUat45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features = np.zeros((len(X_train), 3))\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    X_train_features[i, :] = extract_features(X_train.iloc[i], freqs)"
      ],
      "metadata": {
        "id": "ZoENNnPCZ3k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "EqYgCL7f9ITt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost, theta = gradient_descent(X_train_features, y_train)"
      ],
      "metadata": {
        "id": "0moCgQHraq8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gradient_descent(X_test, theta):\n",
        "  y_preds = []\n",
        "  for sms in X_test:\n",
        "    features = extract_features(sms, freqs)\n",
        "    y_pred = sigmoid(np.matmul(features, theta))\n",
        "    \n",
        "    y_preds.append(round(y_pred.item()))\n",
        "\n",
        "  return y_preds"
      ],
      "metadata": {
        "id": "ixrwtdJF84Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "4jLHuX3N-hhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = test_gradient_descent(X_test, theta)"
      ],
      "metadata": {
        "id": "IzwRvKze-jcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {'acc': accuracy_score(y_preds, y_test), 'f1': f1_score(y_preds, y_test)}"
      ],
      "metadata": {
        "id": "OfqNkx_OBS6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LTF3WP0Bx9J",
        "outputId": "d4268cdd-cbce-4d98-b96f-21e0100b8712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.9325197415649676, 'f1': 0.7526315789473683}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "v4i8gYr7Byk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_preds, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH5jdvW-B205",
        "outputId": "a5a907f4-4974-46c3-8810-88259afeef44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.96      0.96      1206\n",
            "        spam       0.74      0.76      0.75       187\n",
            "\n",
            "    accuracy                           0.93      1393\n",
            "   macro avg       0.85      0.86      0.86      1393\n",
            "weighted avg       0.93      0.93      0.93      1393\n",
            "\n"
          ]
        }
      ]
    }
  ]
}